{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Georgian Digital Alphabet Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "add useful imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turns a number to a one hot array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(values: np.ndarray, max: int) -> np.matrix:\n",
    "    one_hot = np.zeros((values.size, max))\n",
    "    rows = np.arange(values.size)\n",
    "    one_hot[rows, values] = 1    \n",
    "\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import image data and convert images to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as im\n",
    "\n",
    "X_arr = list[np.ndarray]()\n",
    "Y_arr = list[int]()\n",
    "num_chars = ord(\"ჰ\") - ord(\"ა\")\n",
    "\n",
    "for i in range(num_chars):\n",
    "    char = chr(ord(\"ა\") + i)\n",
    "\n",
    "    file_path = f\"data/images/{char}\"\n",
    "    for image in os.listdir(file_path):\n",
    "        img_data = im.imread(f\"{file_path}/{image}\").ravel()\n",
    "\n",
    "        X_arr.append(np.append(img_data, np.ones(10000 - len(img_data))))\n",
    "        Y_arr.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turn list of image values to numpy matrix, values to one_hot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28160, 10000), (28160, 32))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asmatrix(X_arr)\n",
    "Y = to_one_hot(np.asarray(Y_arr), num_chars)\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "divide data to train, validation, and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16896, 10000), (5632, 10000), (5632, 10000))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "division_points = (int(X.shape[0] * 0.6), int(X.shape[0] * 0.8))\n",
    "\n",
    "data = np.append(X, Y, 1)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "X = data[:, 0: X.shape[1]]\n",
    "Y = data[:, X.shape[1]:]\n",
    "\n",
    "X_train = X[0: division_points[0], :]\n",
    "Y_train = Y[0: division_points[0], :]\n",
    "\n",
    "X_valid = X[division_points[0]: division_points[1], :]\n",
    "Y_valid = Y[division_points[0]: division_points[1], :]\n",
    "\n",
    "X_test = X[division_points[1]:, :]\n",
    "Y_test = Y[division_points[1]:, :]\n",
    "\n",
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add normalizarion to the three datas seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train -= X_train.mean(0)\n",
    "X_valid -= X_valid.mean(0)\n",
    "X_test -= X_test.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce dimensions using PCA for data compression reasons\n",
    "find minimum dimension to reduce data to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_dimension = 0\n",
    "\n",
    "sigma = (1 / X_train.shape[0]) * X.T * X\n",
    "u, s, _ = np.linalg.svd(sigma)\n",
    "\n",
    "dimension_sum = 0\n",
    "full_sum = np.sum(s)\n",
    "\n",
    "for k in range(len(s)):\n",
    "    dimension_sum += s[k]\n",
    "    variance_retained = dimension_sum / full_sum\n",
    "\n",
    "    if variance_retained > 0.99:\n",
    "        min_dimension = k\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1902"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reduce data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16896, 1902), (5632, 1902), (5632, 1902))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_reduce = u[:, : min_dimension]\n",
    "\n",
    "X_train = X_train * u_reduce\n",
    "X_valid = X_valid * u_reduce\n",
    "X_test = X_test * u_reduce\n",
    "\n",
    "X_train.shape, X_valid.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define neural network model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkModel:\n",
    "    def __init__(self, in_size: int, out_size: int, hidden_sizes: list[int]) -> None:\n",
    "        self.layers: list[int] = [in_size] + hidden_sizes + [out_size]\n",
    "        \n",
    "        self.thetas = list[np.matrix]()\n",
    "        self.biases = list[np.matrix]()\n",
    "\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            prev_size: int = self.layers[i]\n",
    "            next_size: int = self.layers[i + 1]\n",
    "\n",
    "            # for large inputs dividing by the sqrt of the size helps to keep weight and layer values low\n",
    "            self.thetas.append(np.asmatrix(np.random.standard_normal((next_size, prev_size)) / np.sqrt(in_size)))\n",
    "            self.biases.append(np.asmatrix(np.random.standard_normal((next_size, 1))))\n",
    "\n",
    "    def __ReLU(self, X: np.matrix) -> np.matrix:\n",
    "        return np.maximum(0, X)\n",
    "\n",
    "    def __ReLU_grad(self, X: np.matrix) -> np.matrix:\n",
    "        return np.where(X <= 0, 0, 1)\n",
    "\n",
    "    def __sigmoid(self, X: np.matrix) -> np.matrix:\n",
    "        ephsilon = 1e-5 # to avoid returning 1\n",
    "        X = X.clip(-500, 500) # to prevent overflows\n",
    "\n",
    "        return np.divide(1, 1 + np.exp(-X) + ephsilon)\n",
    "\n",
    "    def __forward(self, input: np.matrix, thetas: list[np.matrix]) -> tuple[np.matrix, list[np.matrix]]:\n",
    "        result: np.matrix = input\n",
    "        layer_values: list[np.matrix] = [input]\n",
    "\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            # z(i)\n",
    "            result = np.dot(result, thetas[i].T)\n",
    "            result = np.add(result, self.biases[i].T)\n",
    "            # a(i)\n",
    "            if i != len(self.layers) - 2: \n",
    "                result = self.__ReLU(result)\n",
    "                layer_values.append(result)\n",
    "\n",
    "            else: result = self.__sigmoid(result)\n",
    "\n",
    "        return result, layer_values\n",
    "\n",
    "    # forward propagation, but returns array with only 1 and 0s\n",
    "    def predict(self, input: np.matrix) -> np.matrix:\n",
    "        # predictions =\n",
    "        return self.__forward(input, self.thetas)\n",
    "        # return to_one_hot(np.asarray(predictions.argmax(axis=1)).ravel(), num_chars)\n",
    "\n",
    "    def cost(self, X: np.matrix, Y: np.matrix, lambd: float, thetas: list[np.matrix]) -> float:\n",
    "        h, _ = self.__forward(X, thetas)\n",
    "\n",
    "        # compute cost\n",
    "        first_term = np.multiply(Y, np.log(h))\n",
    "        second_term = np.multiply((1 - Y), np.log(1 - h))\n",
    "        J = np.sum(first_term + second_term) / (-X.shape[0])\n",
    "\n",
    "        # add regularization\n",
    "        regularized = 0\n",
    "        for thetas in thetas:\n",
    "            regularized += np.sum(np.power(thetas, 2)) * (lambd / (2 * X.shape[0]))\n",
    "\n",
    "        J += regularized\n",
    "\n",
    "        return J\n",
    "    \n",
    "    # backpropagation\n",
    "    def gradients(self, X: np.matrix, Y: np.matrix, lambd: float) -> tuple[list[np.matrix], list[np.matrix]]:\n",
    "        m = X.shape[0]\n",
    "\n",
    "        h, a_values = self.__forward(X, self.thetas)\n",
    "        bias_a = [np.ones((m, 1)) for _ in a_values]\n",
    "\n",
    "        grads = [np.zeros(theta.shape) for theta in self.thetas]\n",
    "        biases = [np.zeros(bias.shape) for bias in self.biases]\n",
    "\n",
    "        # last layer gradients\n",
    "        last_delta = h - Y\n",
    "        grads[-1] = np.dot(last_delta.T, a_values[-1]) / m\n",
    "        grads[-1] += (lambd * self.thetas[-1]) / m  # regulatization\n",
    "\n",
    "        biases[-1] = np.dot(last_delta.T, bias_a[-1]) / m\n",
    "\n",
    "        # hidden layer gradients\n",
    "        for i in reversed(range(1, len(a_values))):\n",
    "            delta = np.multiply(np.dot(last_delta, self.thetas[i]), self.__ReLU_grad(a_values[i]))\n",
    "            last_delta = delta\n",
    "\n",
    "            grads[i - 1] = np.dot(delta.T, a_values[i - 1]) / m\n",
    "            grads[i - 1] += (lambd * self.thetas[i - 1]) / m   # regulatization\n",
    "\n",
    "            biases[i - 1] = np.dot(delta.T, bias_a[i - 1]) / m\n",
    "\n",
    "        return grads, biases\n",
    "\n",
    "    def gradient_check(self, X: np.matrix, Y: np.matrix, lambd: float, grads: list[np.matrix]) -> bool:\n",
    "        ephsilon = 1e-8\n",
    "        \n",
    "        new_theta1 = [np.copy(theta) for theta in self.thetas]\n",
    "        new_theta2 = [np.copy(theta) for theta in self.thetas]\n",
    "        preds = [np.zeros(grad.shape) for grad in grads]\n",
    "        for l in range(len(self.thetas)):\n",
    "            for i in range(self.thetas[l].shape[0]):\n",
    "                for j in range(self.thetas[l].shape[1]):\n",
    "                    new_theta1[l][i, j] = new_theta1[l][i, j] + ephsilon\n",
    "                    new_theta2[l][i, j] = new_theta2[l][i, j] - ephsilon\n",
    "\n",
    "                    grad_pred = self.cost(X, Y, lambd, new_theta1) - self.cost(X, Y, lambd, [theta for theta in new_theta2])\n",
    "                    grad_pred = grad_pred / (2 * ephsilon)\n",
    "                    preds[l][i, j] = grad_pred\n",
    "\n",
    "                    new_theta1[l][i, j] = new_theta1[l][i, j] - ephsilon\n",
    "                    new_theta2[l][i, j] = new_theta2[l][i, j] + ephsilon\n",
    "\n",
    "        flattened_grads = np.concatenate([np.asarray(grad).ravel() for grad in grads])\n",
    "        flattened_preds = np.concatenate([np.asarray(pred).ravel() for pred in preds])\n",
    "\n",
    "        numerator = np.linalg.norm(flattened_grads - flattened_preds)\n",
    "        denominator = np.linalg.norm(flattened_grads) + np.linalg.norm(flattened_preds)\n",
    "        diff = numerator / denominator\n",
    "\n",
    "        if diff > 1e-4:\n",
    "            print(diff)\n",
    "            print(grads) \n",
    "            print(preds)\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def train(self, X: np.matrix, Y: np.matrix, alpha: float, lambd: float, max_iters: int = 1000) -> np.ndarray:\n",
    "        cost = np.zeros(max_iters)\n",
    "\n",
    "        for i in range(max_iters):\n",
    "            theta_grads, bias_grads = self.gradients(X, Y, lambd)\n",
    "\n",
    "            # assert self.gradient_check(X, Y, lambd, theta_grads)\n",
    "\n",
    "            for j, _ in enumerate(self.thetas):\n",
    "                self.thetas[j] = self.thetas[j] - np.multiply(alpha, theta_grads[j])\n",
    "                self.biases[j] = self.biases[j] - np.multiply(alpha, bias_grads[j])\n",
    "\n",
    "            cost[i] = self.cost(X, Y, lambd, self.thetas)\n",
    "\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetworkModel(min_dimension, num_chars, [256, 256, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = nn.train(X_train, Y_train, 0.01, 0.1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([483.71931005, 248.23252941, 299.0897483 , 164.9670367 ,\n",
       "       115.05450566,  86.95498281,  72.57874406,  63.07960315,\n",
       "        56.83461927,  51.78633279,  47.78678482,  44.49881608,\n",
       "        41.71154014,  39.29916756,  37.16082823,  35.21110391,\n",
       "        33.4113442 ,  31.75537007,  30.22129309,  28.76687154,\n",
       "        27.40885829,  26.13379054,  24.93755866,  23.81611377,\n",
       "        22.75722899,  21.768016  ,  20.84306566,  19.97887154,\n",
       "        19.17048304,  18.41756724,  17.70763965,  17.0350812 ,\n",
       "        16.39813242,  15.78159139,  15.19377137,  14.63070255,\n",
       "        14.09935699,  13.58688086,  13.09520515,  12.62016665,\n",
       "        12.16996374,  11.7423301 ,  11.3441904 ,  10.97653921,\n",
       "        10.63053512,  10.30950477,  10.00430379,   9.71914536,\n",
       "         9.44851875,   9.19788715,   8.96385478,   8.7492205 ,\n",
       "         8.54765034,   8.3610537 ,   8.18553112,   8.0272146 ,\n",
       "         7.87669728,   7.75277149,   7.63106202,   7.56422387,\n",
       "         7.46099617,   7.47922781,   7.30184778,   7.38655316,\n",
       "         7.07356179,   7.11060307,   6.82662974,   6.78704165,\n",
       "         6.59877347,   6.5373938 ,   6.40579375,   6.33492324,\n",
       "         6.24020271,   6.17261181,   6.10151862,   6.04108442,\n",
       "         5.98404462,   5.93268957,   5.88499224,   5.84106947,\n",
       "         5.79973529,   5.76136895,   5.72547566,   5.69197211,\n",
       "         5.66046049,   5.63086179,   5.60300951,   5.57680776,\n",
       "         5.55222678,   5.52894266,   5.50677895,   5.48562938,\n",
       "         5.4654694 ,   5.44622767,   5.42788946,   5.41023665,\n",
       "         5.39333294,   5.37708679,   5.36162568,   5.34688239])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "draw the graph of model costs to choose the best alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Error vs. Training Epoch')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vfig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(np.arange(cost.size), cost, 'r')\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Cost')\n",
    "ax.set_title('Error vs. Training Epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "whaat = np.asmatrix([\n",
    "    im.imread(f\"data/images/ა/1_aacadhn.ttf_fs_24_bc_256.ა.png\").ravel(),\n",
    "    im.imread(f\"data/images/ც/132_aacadhn.ttf_fs_40_bc_256.ც.png\").ravel(),\n",
    "    np.zeros(10000)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.predict(whaat)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d80a6ad3f177f820c16ffddce5e20b9780a5a50a827e881a42629beae35f11cc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('Freeuni_ML': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
